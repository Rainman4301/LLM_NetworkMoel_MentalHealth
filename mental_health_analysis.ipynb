{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620d51aa",
   "metadata": {},
   "source": [
    "# Mental Health Analysis ProjectA \n",
    "\n",
    "The purpose of this project is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa92f41",
   "metadata": {},
   "source": [
    "# Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bbce6f",
   "metadata": {},
   "source": [
    "Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39e0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping data from reddit api\n",
    "import requests\n",
    "import pandas as pd\n",
    "# import praw\n",
    "import emoji\n",
    "import emot\n",
    "import asyncpraw\n",
    "# import asyncio\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RedditScraper:\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.auth = requests.auth.HTTPBasicAuth(os.getenv('CLIENT_ID'), os.getenv('CLIENT_SECRET'))\n",
    "        self.data = {'grant_type': 'password',\n",
    "                     'username': os.getenv('USERNAME'),\n",
    "                     'password': os.getenv('PASSWORD')}\n",
    "        self.headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
    "        self.res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                                auth=self.auth, data=self.data, headers=self.headers)\n",
    "        \n",
    "        self.headers[\"Authorization\"] = f'bearer {self.res.json()[\"access_token\"]}'\n",
    "\n",
    "\n",
    "\n",
    "        self.client_id = os.getenv('CLIENT_ID')\n",
    "        self.client_secret = os.getenv('CLIENT_SECRET')\n",
    "        self.username = os.getenv('USERNAME')\n",
    "        self.password = os.getenv('PASSWORD')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_posts_byrequests(self, subreddit, limit=1000):\n",
    "        url = f'https://oauth.reddit.com/r/{subreddit}/hot'\n",
    "        params = {'limit': limit}\n",
    "        response = requests.get(url, headers=self.headers, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            raise Exception(f\"Error fetching posts: {response.status_code} - {response.text}\")\n",
    "        \n",
    "\n",
    "\n",
    "    def convert_emojis_emoticons(self, text):\n",
    "        e = emot.core.emot()\n",
    "\n",
    "        # Extract emoticons\n",
    "        emoticon_results = e.emoticons(text)\n",
    "        for original, meaning in zip(emoticon_results['value'], emoticon_results['mean']):\n",
    "            text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "        # Extract emojis\n",
    "        # emoji_results = e.emoji(text)\n",
    "        # for original, meaning in zip(emoji_results['value'], emoji_results['mean']):\n",
    "        #     text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "        text = emoji.demojize(text)\n",
    "\n",
    "\n",
    "\n",
    "        return text.strip().lower()\n",
    "        \n",
    "\n",
    "\n",
    "    async def get_posts_byprawn(self, subreddits, limit=1000, mental=\"mental_\"):\n",
    "\n",
    "        reddit = asyncpraw.Reddit(client_id=self.client_id,\n",
    "                             client_secret=self.client_secret,\n",
    "                             user_agent='windows:mentalhealth.scraper:v1.0 (by u/IceWorth5480)',\n",
    "                             username=self.username,\n",
    "                             password=self.password)\n",
    "        \n",
    "        all_posts = []\n",
    "        # , 'top', 'new'\n",
    "        sort_types = ['hot']\n",
    "\n",
    "\n",
    "        for subreddit_name in tqdm(subreddits, desc=\"Subreddits Progress\"):\n",
    "            subreddit = await reddit.subreddit(subreddit_name)\n",
    "            for sort in sort_types:\n",
    "                if sort == 'hot':\n",
    "                    posts = subreddit.hot(limit=limit)\n",
    "                elif sort == 'top':\n",
    "                    posts = subreddit.top(limit=limit)\n",
    "                elif sort == 'new':\n",
    "                    posts = subreddit.new(limit=limit)\n",
    "\n",
    "                async for post in posts:\n",
    "                    if post is None:\n",
    "                        continue\n",
    "\n",
    "                    # Load top-level comments (non-blocking)\n",
    "                    await post.load()\n",
    "                    await post.comments.replace_more(limit=0)\n",
    "                    top_comments_raw = [comment.body for comment in post.comments[:5]]  # Get top 5 comments\n",
    "                    top_comments = [self.convert_emojis_emoticons(c) for c in top_comments_raw]\n",
    "\n",
    "                    all_posts.append({\n",
    "                        'id': post.id,\n",
    "                        'subreddit': subreddit_name,\n",
    "                        'sort': sort,\n",
    "                        'title': post.title,\n",
    "                        'selftext': self.convert_emojis_emoticons(post.selftext),\n",
    "                        'created_utc': post.created_utc,\n",
    "                        'score': post.score,\n",
    "                        'num_comments': post.num_comments,\n",
    "                        'author': str(post.author),\n",
    "                        'post_url': post.url,\n",
    "                        'over_18': post.over_18,\n",
    "                        'flair': post.link_flair_text,\n",
    "                        'top_comments': top_comments\n",
    "                    })\n",
    "\n",
    "        await reddit.close()\n",
    "\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(all_posts)\n",
    "        # Drop duplicates by post ID\n",
    "        df = df.drop_duplicates(subset='id').reset_index(drop=True)\n",
    "        df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "        df = df.sort_values(by='created_utc', ascending=False).reset_index(drop=True)\n",
    "        # Convert list of comments to string for CSV storage\n",
    "        df['top_comments'] = df['top_comments'].apply(lambda x: ' | '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "\n",
    "\n",
    "        # check if f'./data/reddit_data/{mental}reddit_posts.csv' exists, if so merging with df and # delete dupicates by id\n",
    "        if os.path.exists(f'./data/reddit_data/{mental}reddit_posts.csv'):\n",
    "            existing_df = pd.read_csv(f'./data/reddit_data/{mental}reddit_posts.csv')\n",
    "            df = pd.concat([existing_df, df]).drop_duplicates(subset='id').reset_index(drop=True)\n",
    "       \n",
    "        # save as csv \n",
    "        df.to_csv(f'./data/reddit_data/{mental}reddit_posts.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3d057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subreddits Progress: 100%|██████████| 4/4 [1:20:33<00:00, 1208.28s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# , 'depression', 'anxiety', 'therapy', 'selfhelp', 'bpd', 'ptsd', 'socialanxiety', 'counseling'\n",
    "mental_subreddits = ['mentalhealth', 'depression', 'anxiety', 'therapy', 'selfhelp', 'bpd', 'ptsd', 'socialanxiety', 'counseling']\n",
    "australian_regions = ['melbourne','sydney','adelaide','perth','brisbane','canberra']\n",
    "normal_subreddits = ['popular','all','AskReddit','interestingasfuck']\n",
    "\n",
    "\n",
    "\n",
    "scraper  = RedditScraper()\n",
    "\n",
    "# await scraper.get_posts_byprawn(mental_subreddits, limit=1000, mental=\"mental_\")\n",
    "await scraper.get_posts_byprawn(normal_subreddits, limit=1000, mental=\"normal_\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7646, 13)\n",
      "(180, 13)\n"
     ]
    }
   ],
   "source": [
    "# read the csv file \n",
    "\n",
    "df_mental = pd.read_csv('./data/reddit_data/mental_reddit_posts.csv')\n",
    "print(df_mental.shape)\n",
    "\n",
    "df_normal = pd.read_csv('./data/reddit_data/normal_reddit_posts.csv')\n",
    "print(df_normal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5613c",
   "metadata": {},
   "source": [
    "Beyond Blue forums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175d8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TO DO\n",
    "\n",
    "Extract following information from the reddit webpage \n",
    "\n",
    "\n",
    "Post ID: A unique identifier for each post.\n",
    "Post Content: The text of the post.\n",
    "Post Author: The author of the post.\n",
    "Post Date: The date the post was made.\n",
    "Post Category: Category or forum where the post was made.\n",
    "Number of Comments: The total number of comments on the post.\n",
    "\n",
    "From Comment \n",
    "\n",
    "Post ID: Link back to the original post.\n",
    "Comment ID: A unique identifier for each comment.\n",
    "Comment Content: Text of the comment.\n",
    "Comment Author: Author of the comment.\n",
    "Comment Date: Date the comment was posted. (the order of the comments is really important)\n",
    "other meta data if available\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import os\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import emot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_post_date(raw_date):\n",
    "\n",
    "    weekdays = [day.lower() for day in list(calendar.day_name) ]\n",
    "    today = datetime.now()\n",
    "\n",
    "    raw_date = raw_date.strip().lower()  \n",
    "\n",
    "    # Case 1: Day of the week (e.g., \"Monday\")\n",
    "    if raw_date in weekdays:\n",
    "        # Get weekday index: Monday = 0, Sunday = 6\n",
    "        post_weekday_index = weekdays.index(raw_date)\n",
    "        today_weekday_index = today.weekday()\n",
    "\n",
    "        # Calculate difference in days\n",
    "        delta_days = (today_weekday_index - post_weekday_index) % 7\n",
    "        # Get actual date\n",
    "        post_date = today - timedelta(days=delta_days)\n",
    "        return post_date.strftime('%Y-%m-%d')  # Format as YYYY-MM-DD\n",
    "    \n",
    "    # Case 2: \"a week ago\", \"2 weeks ago\", etc.\n",
    "    elif \"week\" in raw_date:\n",
    "        match = re.search(r'(\\d+)', raw_date)\n",
    "        weeks = int(match.group(1)) if match else 1\n",
    "        post_date = today - timedelta(weeks=weeks)\n",
    "        return post_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Case 3: \"a month ago\", \"2 months ago\", etc.\n",
    "    elif \"month\" in raw_date:\n",
    "        match = re.search(r'(\\d+)', raw_date)\n",
    "        months = int(match.group(1)) if match else 1\n",
    "        # Approximate a month as 30 days\n",
    "        post_date = today - timedelta(days=30 * months)\n",
    "        return post_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Case 4: Exact date format like \"11-05-2025\"\n",
    "    else:\n",
    "        # Try parsing date in the format like \"25-09-2020\"\n",
    "        try:\n",
    "            post_date = datetime.strptime(raw_date, '%d-%m-%Y')\n",
    "            return post_date.strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return 'Unknown date'  # If format is unexpected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_emojis_emoticons(text):\n",
    "    e = emot.core.emot()\n",
    "\n",
    "    # Extract emoticons\n",
    "    emoticon_results = e.emoticons(text)\n",
    "\n",
    "    for original, meaning in zip(emoticon_results['value'], emoticon_results['mean']):\n",
    "        text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "    # # Extract emojis\n",
    "    # emoji_results = e.emoji(text)\n",
    "    # for original, meaning in zip(emoji_results['value'], emoji_results['mean']):\n",
    "    #     text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def comment_scrapping (url, comment_pages = 1):\n",
    "\n",
    "    \n",
    "    # Setup Chrome WebDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    comment_driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    list_comments = []\n",
    "\n",
    "    for page in range(1, comment_pages + 1):\n",
    "\n",
    "        comment_driver.get(url)\n",
    "        time.sleep(0.005)\n",
    "        soup = BeautifulSoup(comment_driver.page_source, 'html.parser')\n",
    "        comments_section = soup.find('div', class_='linear-message-list message-list')\n",
    "        every_comments = comments_section.find_all('div')\n",
    "\n",
    "\n",
    "        for comment in every_comments:\n",
    "\n",
    "            main_section = comment.find('div', class_='lia-quilt-row lia-quilt-row-message-main') if comment.find('div', class_='lia-quilt-row lia-quilt-row-message-main') else None\n",
    "            if not main_section:\n",
    "                continue\n",
    "            # scrapping all the text \n",
    "            comment_text = main_section.get_text(separator=' ', strip=True) if main_section else \"\"\n",
    "            comment_text = convert_emojis_emoticons(comment_text)\n",
    "            list_comments.append(comment_text)\n",
    "\n",
    "            # only scrapping the first 3 comments\n",
    "            if len(list_comments) >= 3:\n",
    "                break\n",
    "\n",
    "        # Find next page link\n",
    "        next_page = soup.find('li', class_='lia-paging-page-next')\n",
    "        if next_page and next_page.find('a'):\n",
    "            next_page_link = next_page.find('a')['href']\n",
    "            url = next_page_link\n",
    "        else:\n",
    "            print(\"No more pages to scrape.\")\n",
    "            break\n",
    "        \n",
    "    # close the driver\n",
    "    comment_driver.quit()\n",
    "\n",
    "    # change the list of comments to a string\n",
    "    list_comments = ' | '.join(list_comments) if list_comments else \"\"\n",
    "    \n",
    "\n",
    "    return list_comments\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def beyondblue_scrapping(tag,address,pages=2):\n",
    "\n",
    "\n",
    "    # Setup Chrome WebDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    url = address\n",
    "\n",
    "    whole_data = []\n",
    "\n",
    "\n",
    "\n",
    "    for page in tqdm(range(1, pages + 1), desc=\"Scraping pages\"):\n",
    "\n",
    "    \n",
    "        driver.get(url)\n",
    "        # time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "\n",
    "        # get the class \"custom-message-list all-discussions\"\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "\n",
    "        discussions = soup.find('div', class_='custom-message-list all-discussions').find_all(('article'))\n",
    "        \n",
    "\n",
    "        for post in discussions:\n",
    "\n",
    "            # Extracting post id\n",
    "            post_link = post.find('h3').find_all('a')[1].get('href')\n",
    "            post_id = post_link.split('/')[-1]  \n",
    "\n",
    "\n",
    "            full_post_link = f\"https://forums.beyondblue.org.au{post_link}\"\n",
    "            # extract comments from post_link\n",
    "            comments = comment_scrapping(full_post_link, comment_pages=1)\n",
    "            \n",
    "\n",
    "            # Extracting post title\n",
    "            title_tag = post.find_all('h3')[0].find_all('a')[1]\n",
    "            post_title = convert_emojis_emoticons(title_tag.text.strip()) if title_tag else \"\"\n",
    "\n",
    "            # Extracting post content\n",
    "            post_content = convert_emojis_emoticons(post.find('p', class_ = 'body-text').text.strip()) if post.find('p', class_ = 'body-text') else \"\"\n",
    "            \n",
    "\n",
    "            side_info = post.find('aside')\n",
    "            side_info1 = side_info.find('div', class_='custom-tile-author-info') if side_info else None\n",
    "            # Extracting post author\n",
    "            post_author = side_info1.find('a').find('span').text.strip() if side_info and side_info.find('span') else \"\"\n",
    "\n",
    "            author_link = post.find('aside').find('div', class_='custom-tile-author-info').find('a').get('href')\n",
    "            # Extracting user id from author link\n",
    "            user_id = author_link.split('user-id/')[-1]\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            side_info2 = side_info.find('div', class_='custom-tile-category-content')\n",
    "            # Extracting post tag\n",
    "            post_tag = side_info2.find('a').text.strip() if side_info2 and side_info2.find('a') else \"\"\n",
    "            \n",
    "            \n",
    "            raw_date = side_info2.find('time').text.strip() if side_info2 and side_info2.find('time') else \"\"\n",
    "            # Extracting post date\n",
    "            post_date = parse_post_date(raw_date)\n",
    "\n",
    "\n",
    "\n",
    "            side_info3 = side_info.find('div', class_='custom-tile-unread-replies')\n",
    "            unread = side_info3.find('span').text.strip() if side_info3 and side_info3.find('span') else \"\"\n",
    "            # Extracting number of unread replies\n",
    "            match = re.search(r'\\d+', unread)\n",
    "            post_unread = int(match.group()) if match else 0\n",
    "\n",
    "            # Extracting number of comments\n",
    "            number_comments = post.find('li', class_ = 'custom-tile-replies').find('b').text.strip() if post.find('li', class_ = 'custom-tile-replies') else \"\"\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            post_data = {\n",
    "                \"Post ID\": post_id,\n",
    "                \"Post Title\": post_title,\n",
    "                \"Post Content\": post_content,\n",
    "                \"Post Author\": post_author,\n",
    "                \"User ID\": user_id,\n",
    "                \"Post Date\": post_date,\n",
    "                \"Post Category\": post_tag,\n",
    "                \"Number of Comments\": number_comments,\n",
    "                \"Comments\": comments\n",
    "            }\n",
    "            whole_data.append(post_data)\n",
    "\n",
    "\n",
    "        # Print the number of posts scraped on the current page\n",
    "        # print(f\"Tag: {tag} Page {page}: Scraped {len(discussions)} posts.\")\n",
    "\n",
    "        # Find next page link\n",
    "        next_page = soup.find('li', class_='lia-paging-page-next')\n",
    "        if next_page and next_page.find('a'):\n",
    "            url = next_page.find('a')['href']\n",
    "        else:\n",
    "            print(\"No more pages to scrape.\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if page % 50 == 0:\n",
    "            # save the data to a csv file\n",
    "            temp_df = pd.DataFrame(whole_data)\n",
    "            temp_df = temp_df.drop_duplicates(subset='Post ID').reset_index(drop=True)\n",
    "            temp_df['Post Date'] = pd.to_datetime(temp_df['Post Date'], errors='coerce')\n",
    "            temp_df = temp_df.sort_values(by='Post Date', ascending=False).reset_index(drop=True)\n",
    "            # check if the file already exists\n",
    "            if not os.path.exists(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv'):\n",
    "                temp_df.to_csv(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv', index=False)\n",
    "            else:\n",
    "                existing_df = pd.read_csv(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv')\n",
    "                temp_df = pd.concat([existing_df, temp_df]).drop_duplicates(subset='Post ID').reset_index(drop=True)\n",
    "                temp_df.to_csv(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv', index=False)\n",
    "\n",
    "            print(f'The data for tag {tag} has been scraped to page {page}')\n",
    "\n",
    "            # if the oldest post is older than 2020-01-01, stop the scraping\n",
    "            # if not temp_df.empty and temp_df['Post Date'].min() < pd.to_datetime('2020-01-01'):\n",
    "            #     print(f\"The oldest post is older than 2020-01-01, stopping the scraping for tag {tag}.\")\n",
    "            #     break\n",
    "\n",
    "\n",
    "    #close the driver\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Convert to DataFrame \n",
    "    df = pd.DataFrame(whole_data)\n",
    "    # delete duplicates by Post ID\n",
    "    df = df.drop_duplicates(subset='Post ID').reset_index(drop=True)\n",
    "    # Convert 'Post Date' to datetime format\n",
    "    df['Post Date'] = pd.to_datetime(df['Post Date'], errors='coerce')\n",
    "    # Sort by 'Post Date' in descending order\n",
    "    df = df.sort_values(by='Post Date', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # check if the file already exists\n",
    "    if os.path.exists(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv'):\n",
    "        existing_df = pd.read_csv(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv')\n",
    "        df = pd.concat([existing_df, df]).drop_duplicates(subset='Post ID').reset_index(drop=True)\n",
    "\n",
    "    df.to_csv(f'./data/beyondblue_data/{tag}_beyondblue_posts.csv', index=False)\n",
    "        \n",
    "        \n",
    "    print(f\"Data saved to ./data/beyondblue_data/{tag}_beyondblue_posts.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  33%|███▎      | 50/150 [1:09:34<2:19:39, 83.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Anxiety has been scraped to page 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  67%|██████▋   | 100/150 [2:18:21<1:09:11, 83.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Anxiety has been scraped to page 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages: 100%|██████████| 150/150 [3:27:40<00:00, 83.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Anxiety has been scraped to page 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./data/beyondblue_data/Anxiety_beyondblue_posts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  33%|███▎      | 49/150 [1:07:40<2:19:05, 82.63s/it]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29512\\715762650.py:289: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_df['Post Date'] = pd.to_datetime(temp_df['Post Date'], errors='coerce')\n",
      "Scraping pages:  33%|███▎      | 50/150 [1:09:02<2:17:28, 82.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Depression has been scraped to page 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  66%|██████▌   | 99/150 [2:16:01<1:10:43, 83.20s/it]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29512\\715762650.py:289: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_df['Post Date'] = pd.to_datetime(temp_df['Post Date'], errors='coerce')\n",
      "Scraping pages:  67%|██████▋   | 100/150 [2:17:26<1:09:42, 83.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Depression has been scraped to page 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  99%|█████████▉| 149/150 [3:25:22<01:23, 83.40s/it]  C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29512\\715762650.py:289: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  temp_df['Post Date'] = pd.to_datetime(temp_df['Post Date'], errors='coerce')\n",
      "Scraping pages: 100%|██████████| 150/150 [3:26:46<00:00, 82.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag Depression has been scraped to page 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_29512\\715762650.py:319: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Post Date'] = pd.to_datetime(df['Post Date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./data/beyondblue_data/Depression_beyondblue_posts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  33%|███▎      | 50/150 [1:08:19<2:18:45, 83.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag PTSD has been scraped to page 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:  67%|██████▋   | 100/150 [2:17:02<1:09:31, 83.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag PTSD has been scraped to page 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages: 100%|██████████| 150/150 [3:25:18<00:00, 82.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for tag PTSD has been scraped to page 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./data/beyondblue_data/PTSD_beyondblue_posts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping pages:   0%|          | 0/150 [00:45<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tag, address \u001b[38;5;129;01min\u001b[39;00m mental_health_urls.items():\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         \u001b[43mbeyondblue_scrapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     28\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError scraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mbeyondblue_scrapping\u001b[39m\u001b[34m(tag, address, pages)\u001b[39m\n\u001b[32m    206\u001b[39m full_post_link = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://forums.beyondblue.org.au\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpost_link\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# extract comments from post_link\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m comments = \u001b[43mcomment_scrapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_post_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# Extracting post title\u001b[39;00m\n\u001b[32m    212\u001b[39m title_tag = post.find_all(\u001b[33m'\u001b[39m\u001b[33mh3\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m].find_all(\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mcomment_scrapping\u001b[39m\u001b[34m(url, comment_pages)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomment_scrapping\u001b[39m (url, comment_pages = \u001b[32m1\u001b[39m):\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# Setup Chrome WebDriver\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     service = Service(\u001b[43mChromeDriverManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    120\u001b[39m     comment_driver = webdriver.Chrome(service=service)\n\u001b[32m    125\u001b[39m     list_comments = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\chrome.py:40\u001b[39m, in \u001b[36mChromeDriverManager.install\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minstall\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     driver_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_driver_binary_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     os.chmod(driver_path, \u001b[32m0o755\u001b[39m)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m driver_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\manager.py:35\u001b[39m, in \u001b[36mDriverManager._get_driver_binary_path\u001b[39m\u001b[34m(self, driver)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_driver_binary_path\u001b[39m(\u001b[38;5;28mself\u001b[39m, driver):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     binary_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cache_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary_path:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m binary_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\driver_cache.py:107\u001b[39m, in \u001b[36mDriverCacheManager.find_driver\u001b[39m\u001b[34m(self, driver)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m browser_version:\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m driver_version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_cache_key_driver_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m metadata = \u001b[38;5;28mself\u001b[39m.load_metadata_content()\n\u001b[32m    110\u001b[39m key = \u001b[38;5;28mself\u001b[39m.__get_metadata_key(driver)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\driver_cache.py:154\u001b[39m, in \u001b[36mDriverCacheManager.get_cache_key_driver_version\u001b[39m\u001b[34m(self, driver)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_key_driver_version:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_key_driver_version\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_driver_version_to_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\driver.py:48\u001b[39m, in \u001b[36mDriver.get_driver_version_to_download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._driver_version_to_download:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._driver_version_to_download\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_latest_release_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\drivers\\chrome.py:55\u001b[39m, in \u001b[36mChromeDriver.get_latest_release_version\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_latest_release_version\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     determined_browser_version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_browser_version_from_os\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     log(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGet LATEST \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m version for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._browser_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m determined_browser_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m version.parse(determined_browser_version) >= version.parse(\u001b[33m\"\u001b[39m\u001b[33m115\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\driver.py:63\u001b[39m, in \u001b[36mDriver.get_browser_version_from_os\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mUse-cases:\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03m- for key in metadata;\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03mNote: the fallback may have collisions in user cases when previous browser was not uninstalled properly.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._browser_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28mself\u001b[39m._browser_version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_os_system_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_browser_version_from_os\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_browser_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._browser_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\os_manager.py:78\u001b[39m, in \u001b[36mOperationSystemManager.get_browser_version_from_os\u001b[39m\u001b[34m(self, browser_type)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_browser_version_from_os\u001b[39m(\u001b[38;5;28mself\u001b[39m, browser_type=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     68\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return installed browser version.\"\"\"\u001b[39;00m\n\u001b[32m     69\u001b[39m     cmd_mapping = {\n\u001b[32m     70\u001b[39m         ChromeType.GOOGLE: {\n\u001b[32m     71\u001b[39m             OSType.LINUX: linux_browser_apps_to_cmd(\n\u001b[32m     72\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mgoogle-chrome\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     73\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mgoogle-chrome-stable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mgoogle-chrome-beta\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mgoogle-chrome-dev\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     76\u001b[39m             ),\n\u001b[32m     77\u001b[39m             OSType.MAC: \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Applications/Google\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Chrome.app/Contents/MacOS/Google\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Chrome --version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m             OSType.WIN: \u001b[43mwindows_browser_apps_to_cmd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(Get-Item -Path \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$env:PROGRAMFILES\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGoogle\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mChrome\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mApplication\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mchrome.exe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).VersionInfo.FileVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(Get-Item -Path \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$env:PROGRAMFILES (x86)\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGoogle\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mChrome\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mApplication\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mchrome.exe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).VersionInfo.FileVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(Get-Item -Path \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$env:LOCALAPPDATA\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGoogle\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mChrome\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mApplication\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mchrome.exe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).VersionInfo.FileVersion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(Get-ItemProperty -Path Registry::\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHKCU\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mSOFTWARE\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGoogle\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mChrome\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mBLBeacon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).version\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(Get-ItemProperty -Path Registry::\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHKLM\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mSOFTWARE\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mWow6432Node\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mMicrosoft\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mWindows\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mCurrentVersion\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUninstall\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGoogle Chrome\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m).version\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     85\u001b[39m         },\n\u001b[32m     86\u001b[39m         ChromeType.CHROMIUM: {\n\u001b[32m     87\u001b[39m             OSType.LINUX: linux_browser_apps_to_cmd(\u001b[33m\"\u001b[39m\u001b[33mchromium\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mchromium-browser\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     88\u001b[39m             OSType.MAC: \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Applications/Chromium.app/Contents/MacOS/Chromium --version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m             OSType.WIN: windows_browser_apps_to_cmd(\n\u001b[32m     90\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mChromium\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mchrome.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     91\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mChromium\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mchrome.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     92\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:LOCALAPPDATA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mChromium\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mchrome.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     93\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mChromium\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     94\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKLM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWow6432Node\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUninstall\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mChromium\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     95\u001b[39m             ),\n\u001b[32m     96\u001b[39m         },\n\u001b[32m     97\u001b[39m         ChromeType.BRAVE: {\n\u001b[32m     98\u001b[39m             OSType.LINUX: linux_browser_apps_to_cmd(\n\u001b[32m     99\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbrave-browser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbrave-browser-beta\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbrave-browser-nightly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m             ),\n\u001b[32m    101\u001b[39m             OSType.MAC: \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Applications/Brave\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Browser.app/Contents/MacOS/Brave\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Browser --version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m             OSType.WIN: windows_browser_apps_to_cmd(\n\u001b[32m    103\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBraveSoftware\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBrave-Browser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    104\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBraveSoftware\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBrave-Browser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    105\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:LOCALAPPDATA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBraveSoftware\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBrave-Browser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbrave.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    106\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBraveSoftware\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBrave-Browser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    107\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKLM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWow6432Node\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUninstall\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBraveSoftware Brave-Browser\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    108\u001b[39m             ),\n\u001b[32m    109\u001b[39m         },\n\u001b[32m    110\u001b[39m         ChromeType.MSEDGE: {\n\u001b[32m    111\u001b[39m             OSType.LINUX: linux_browser_apps_to_cmd(\n\u001b[32m    112\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmicrosoft-edge\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmicrosoft-edge-stable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmicrosoft-edge-beta\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmicrosoft-edge-dev\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m             ),\n\u001b[32m    117\u001b[39m             OSType.MAC: \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Applications/Microsoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Edge.app/Contents/MacOS/Microsoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m Edge --version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m             OSType.WIN: windows_browser_apps_to_cmd(\n\u001b[32m    119\u001b[39m                 \u001b[38;5;66;03m# stable edge\u001b[39;00m\n\u001b[32m    120\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    121\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    122\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    123\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKLM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdgeUpdate\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mClients\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m{\u001b[39m\u001b[33m56EB18F8-8008-4CBD-B6D2-8C97FE7E9062}\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).pv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    124\u001b[39m                 \u001b[38;5;66;03m# beta edge\u001b[39;00m\n\u001b[32m    125\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:LOCALAPPDATA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Beta\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    126\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Beta\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    127\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Beta\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    128\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Beta\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    129\u001b[39m                 \u001b[38;5;66;03m# dev edge\u001b[39;00m\n\u001b[32m    130\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:LOCALAPPDATA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Dev\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    131\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Dev\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    132\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Dev\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    133\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge Dev\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    134\u001b[39m                 \u001b[38;5;66;03m# canary edge\u001b[39;00m\n\u001b[32m    135\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:LOCALAPPDATA\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge SxS\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApplication\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    136\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKCU\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEdge SxS\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBLBeacon\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    137\u001b[39m                 \u001b[38;5;66;03m# highest edge\u001b[39;00m\n\u001b[32m    138\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(Get-Item (Get-ItemProperty \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHKLM:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApp Paths\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Default)\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).VersionInfo.ProductVersion\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    139\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[System.Diagnostics.FileVersionInfo]::GetVersionInfo((Get-ItemProperty \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHKLM:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApp Paths\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mmsedge.exe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Default)\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).ProductVersion\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    140\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGet-AppxPackage -Name *MicrosoftEdge.* | Foreach Version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    141\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKLM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWow6432Node\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUninstall\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft Edge\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).version\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    142\u001b[39m             ),\n\u001b[32m    143\u001b[39m         },\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfirefox\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    145\u001b[39m             OSType.LINUX: linux_browser_apps_to_cmd(\u001b[33m\"\u001b[39m\u001b[33mfirefox\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    146\u001b[39m             OSType.MAC: \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Applications/Firefox.app/Contents/MacOS/firefox --version\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    147\u001b[39m             OSType.WIN: windows_browser_apps_to_cmd(\n\u001b[32m    148\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMozilla Firefox\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfirefox.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    149\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-Item -Path \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m$env:PROGRAMFILES (x86)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMozilla Firefox\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfirefox.exe\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).VersionInfo.FileVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    150\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(Get-Item (Get-ItemProperty \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHKLM:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMicrosoft\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mWindows\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCurrentVersion\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mApp Paths\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfirefox.exe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Default)\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).VersionInfo.ProductVersion\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    151\u001b[39m                 \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(Get-ItemProperty -Path Registry::\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHKLM\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSOFTWARE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMozilla\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mMozilla Firefox\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m).CurrentVersion\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    152\u001b[39m             ),\n\u001b[32m    153\u001b[39m         },\n\u001b[32m    154\u001b[39m     }\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    157\u001b[39m         cmd_mapping = cmd_mapping[browser_type][OperationSystemManager.get_os_name()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\utils.py:28\u001b[39m, in \u001b[36mwindows_browser_apps_to_cmd\u001b[39m\u001b[34m(*apps)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwindows_browser_apps_to_cmd\u001b[39m(*apps: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create analogue of browser --version command for windows.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     powershell = \u001b[43mdetermine_powershell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     first_hit_template = \u001b[33m\"\"\"\u001b[39m\u001b[33m$tmp = \u001b[39m\u001b[38;5;132;01m{expression}\u001b[39;00m\u001b[33m; if ($tmp) \u001b[39m\u001b[33m{{\u001b[39m\u001b[33mecho $tmp; Exit;}};\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     31\u001b[39m     script = \u001b[33m\"\u001b[39m\u001b[33m$ErrorActionPreference=\u001b[39m\u001b[33m'\u001b[39m\u001b[33msilentlycontinue\u001b[39m\u001b[33m'\u001b[39m\u001b[33m; \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     32\u001b[39m         first_hit_template.format(expression=e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m apps\n\u001b[32m     33\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\site-packages\\webdriver_manager\\core\\utils.py:62\u001b[39m, in \u001b[36mdetermine_powershell\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     54\u001b[39m cmd = \u001b[33m\"\u001b[39m\u001b[33m(dir 2>&1 *`|echo CMD);&<# rem #>echo powershell\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m subprocess.Popen(\n\u001b[32m     56\u001b[39m         cmd,\n\u001b[32m     57\u001b[39m         stdout=subprocess.PIPE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m         shell=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     61\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     stdout = \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].decode()\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stdout == \u001b[33m\"\u001b[39m\u001b[33mpowershell\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpowershell\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda3\\envs\\MDS\\Lib\\subprocess.py:1196\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28mself\u001b[39m._stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout:\n\u001b[32m-> \u001b[39m\u001b[32m1196\u001b[39m     stdout = \u001b[38;5;28mself\u001b[39m.stdout.read()\n\u001b[32m   1197\u001b[39m     \u001b[38;5;28mself\u001b[39m.stdout.close()\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stderr:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# post_variables = [\"Post ID\", \"Post Content\", \"Post Author\", \"Post Date\", \"Post Category\", \"Number of Comments\"]\n",
    "# mental_health_type =['Anxiety','Depression','PTSD and trauma','Suicidal thoughts and self-harm']\n",
    "\n",
    "\n",
    "\n",
    "mental_health_urls = {\n",
    "    # \"Anxiety\": \"https://forums.beyondblue.org.au/t5/anxiety/bd-p/c1-sc2-b1?&sort=recent\",\n",
    "    # \"Depression\": \"https://forums.beyondblue.org.au/t5/depression/bd-p/c1-sc2-b2?&sort=recent\",\n",
    "    # \"PTSD\": \"https://forums.beyondblue.org.au/t5/ptsd-and-trauma/bd-p/c1-sc2-b3?&sort=recent\",\n",
    "    \"Suicide_selfharm\": \"https://forums.beyondblue.org.au/t5/suicidal-thoughts-and-self-harm/bd-p/c1-sc2-b4?&sort=recent\",\n",
    "    # \"Staying_well\": \"https://forums.beyondblue.org.au/t5/staying-well/bd-p/c1-sc3-b1?&sort=recent\",\n",
    "    # \"Treament\": \"https://forums.beyondblue.org.au/t5/treatments-health-professionals/bd-p/c1-sc3-b2?&sort=recent\",\n",
    "    # \"Relationship_family_issues\":\"https://forums.beyondblue.org.au/t5/relationship-and-family-issues/bd-p/c1-sc3-b3?&sort=recent\",\n",
    "    \"Youth\":\"https://forums.beyondblue.org.au/t5/young-people/bd-p/c1-sc4-b1?&sort=recent\",\n",
    "    \"Sex_identity\":\"https://forums.beyondblue.org.au/t5/sexuality-and-gender-identity/bd-p/c1-sc4-b2?&sort=recent\",\n",
    "    \"Multiculture\":\"https://forums.beyondblue.org.au/t5/multicultural-experiences/bd-p/c1-sc4-b3?&sort=recent\",\n",
    "    \"Grief_loss\":\"https://forums.beyondblue.org.au/t5/grief-and-loss/bd-p/c1-sc4-b4?&sort=recent\"\n",
    "}\n",
    "\n",
    "each_tag_number_data = 1500\n",
    "pages = each_tag_number_data // 10  # Assuming each page has 10 posts\n",
    "\n",
    "\n",
    "for tag, address in mental_health_urls.items():\n",
    "    try:\n",
    "        beyondblue_scrapping(tag, address, pages = pages)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {tag}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087e68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read the csv file\n",
    "\n",
    "df_anxiety = pd.read_csv('./data/beyondblue_data/Anxiety_beyondblue_posts.csv')\n",
    "print(df_anxiety.shape)\n",
    "# print(df_anxiety)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf93aa",
   "metadata": {},
   "source": [
    "Climate data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a8c195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected ZIP URL for Adelaide - Temp_Min: https://reg.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_display_type=dailyZippedDataFile&p_stn_num=023000&p_c=-105845614&p_nccObsCode=123&p_startYear=2025\n",
      "Collected ZIP URL for Hobart - Temp_Min: https://reg.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_display_type=dailyZippedDataFile&p_stn_num=094029&p_c=-1768336182&p_nccObsCode=123&p_startYear=2025\n",
      "\n",
      "All collected ZIP URLs:\n",
      "SA_Adelaide_Temp_Min: https://reg.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_display_type=dailyZippedDataFile&p_stn_num=023000&p_c=-105845614&p_nccObsCode=123&p_startYear=2025\n",
      "TAS_Hobart_Temp_Min: https://reg.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_display_type=dailyZippedDataFile&p_stn_num=094029&p_c=-1768336182&p_nccObsCode=123&p_startYear=2025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "url = \"https://reg.bom.gov.au/climate/data/\"\n",
    "\n",
    "# weather_types = ['Rainfall', 'Temp_Max', 'Temp_Min', 'Solar exposure']\n",
    "# australian_regions = ['NSW', 'VIC', 'QLD', 'WA', 'SA', 'TAS', 'ACT', 'NT']\n",
    "# australian_citys = ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Hobart', 'Canberra', 'Darwin']\n",
    "\n",
    "weather_types = ['Temp_Min']\n",
    "australian_regions = ['SA', 'TAS']\n",
    "australian_citys = ['Adelaide', 'Hobart']\n",
    "\n",
    "zip_url = {}\n",
    "\n",
    "for weather_type in weather_types:\n",
    "    for region, city in zip(australian_regions, australian_citys):\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "\n",
    "            # Select weather type\n",
    "            data_about_dropdown = wait.until(EC.presence_of_element_located((By.ID, 'ncc_obs_code_group')))\n",
    "\n",
    "            if weather_type == 'Rainfall':\n",
    "                data_about_dropdown.find_element(By.XPATH, \"//option[text()='Rainfall']\").click()\n",
    "\n",
    "            elif weather_type == 'Temp_Max':\n",
    "                data_about_dropdown.find_element(By.XPATH, \"//option[text()='Temperature']\").click()\n",
    "\n",
    "                # ✅ Wait for the secondary dropdown to become visible\n",
    "                sub_select = wait.until(EC.visibility_of_element_located((By.ID, 'elementSubSelectLine')))\n",
    "                time.sleep(1)\n",
    "\n",
    "                # ✅ Select Maximum Temperature\n",
    "                element_select = driver.find_element(By.ID, 'elementSubSelect')\n",
    "                element_select.find_element(By.XPATH, \"//option[text()='Maximum temperature']\").click()\n",
    "\n",
    "            elif weather_type == 'Temp_Min':\n",
    "                data_about_dropdown.find_element(By.XPATH, \"//option[text()='Temperature']\").click()\n",
    "\n",
    "                # ✅ Wait for the secondary dropdown to become visible\n",
    "                sub_select = wait.until(EC.visibility_of_element_located((By.ID, 'elementSubSelectLine')))\n",
    "                time.sleep(1)\n",
    "\n",
    "                # ✅ Select Minimum Temperature (fixed typo)\n",
    "                element_select = driver.find_element(By.ID, 'elementSubSelect')\n",
    "                element_select.find_element(By.XPATH, \"//option[text()='Minimum temperature']\").click()\n",
    "\n",
    "\n",
    "            elif weather_type == 'Solar exposure':\n",
    "                data_about_dropdown.find_element(By.XPATH, \"//option[text()='Solar exposure']\").click()\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Input city\n",
    "            location_input = driver.find_element(By.ID, 'p_locSearch')\n",
    "            location_input.clear()\n",
    "            location_input.send_keys(city)\n",
    "\n",
    "            # Click Find button\n",
    "            find_button = driver.find_element(By.ID, 'text')\n",
    "            find_button.click()\n",
    "\n",
    "            time.sleep(4)\n",
    "\n",
    "            # Select the first matching town\n",
    "            match_list = wait.until(EC.presence_of_element_located((By.ID, 'matchList')))\n",
    "            match_list.find_elements(By.TAG_NAME, 'option')[0].click()\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Tick 'Only show open stations'\n",
    "            open_station_checkbox = driver.find_element(By.ID, 'openStation')\n",
    "            if not open_station_checkbox.is_selected():\n",
    "                open_station_checkbox.click()\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Select the first available station\n",
    "            nearest_stations = wait.until(EC.presence_of_element_located((By.ID, 'nearest10')))\n",
    "            station_options = nearest_stations.find_elements(By.TAG_NAME, 'option')\n",
    "            if len(station_options) == 0:\n",
    "                print(f'No stations found for {city} - {weather_type}')\n",
    "                driver.quit()\n",
    "                continue\n",
    "\n",
    "            station_options[0].click()\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Click Get Data button \n",
    "            get_data_button = driver.find_element(By.ID, 'getData')\n",
    "            time.sleep(5)  \n",
    "            get_data_button.click()\n",
    "\n",
    "            time.sleep(5)  # Allow time for the new page to load\n",
    "\n",
    "            # Switch to the new tab\n",
    "            driver.switch_to.window(driver.window_handles[-1])\n",
    "\n",
    "            # Wait for the downloads list to appear\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'downloads')))\n",
    "\n",
    "            # Scrape the All Years of Data link\n",
    "            all_years_link = driver.find_element(By.LINK_TEXT, 'All years of data')\n",
    "            href = all_years_link.get_attribute('href')\n",
    "\n",
    "            # Save the link\n",
    "            zip_url_key = f'{region}_{city}_{weather_type}'\n",
    "            zip_url[zip_url_key] = href\n",
    "\n",
    "            print(f'Collected ZIP URL for {city} - {weather_type}: {href}')\n",
    "\n",
    "            driver.close()  # Close the data tab\n",
    "            driver.switch_to.window(driver.window_handles[0])  # Switch back to the main tab\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {city} - {weather_type}: {e}')\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "# Display all collected URLs\n",
    "print(\"\\nAll collected ZIP URLs:\")\n",
    "for key, link in zip_url.items():\n",
    "    print(f'{key}: {link}')\n",
    "\n",
    "\n",
    "# Save the URLs to a CSV file\n",
    "df_urls = pd.DataFrame(list(zip_url.items()), columns=['Region_City_WeatherType', 'ZIP_URL'])\n",
    "df_urls.to_csv('./data/AUS_weather/complement.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c274975",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53210b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# download the zip files from the bom website and extract the data\n",
    "# and save the data to a csv file with the name of the region and city\n",
    "# delete the zip file after extracting the data\n",
    "\n",
    "for region, city in zip(australian_regions, australian_citys):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78036975",
   "metadata": {},
   "source": [
    "# Nature Language Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5648be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------------------- -------------------- 6.3/12.8 MB 38.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 33.5 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e458a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')  # For tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3897e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import emoji\n",
    "import emot\n",
    "\n",
    "class NLP_OPERATORS:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "        self.nlp.max_length = 5_000_000\n",
    "\n",
    "    def convert_emojis_emoticons(self, text):\n",
    "        e = emot.core.emot()\n",
    "\n",
    "        # Extract emoticons\n",
    "        emoticon_results = e.emoticons(text)\n",
    "        for original, meaning in zip(emoticon_results['value'], emoticon_results['mean']):\n",
    "            text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "        # # Extract emojis\n",
    "        # emoji_results = e.emoji(text)\n",
    "        # for original, meaning in zip(emoji_results['value'], emoji_results['mean']):\n",
    "        #     text = text.replace(original, f\" {meaning} \")\n",
    "\n",
    "\n",
    "        # Convert emojis to text\n",
    "        text = emoji.demojize(text)\n",
    "\n",
    "        return text.strip().lower()\n",
    "\n",
    "    def basic_cleaning(self, text):\n",
    "        \n",
    "        # Convert emojis and emoticons to text\n",
    "        text = self.convert_emojis_emoticons(text)\n",
    "        # Remove unwanted characters and patterns\n",
    "        text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "        # Remove URLs, HTML tags, extra spaces, and special characters\n",
    "        text = re.sub(r'https?://\\S+', '', text)\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        # remove extra spaces and quotes\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove quotes\n",
    "        text = re.sub(r'&quot;', '', text)\n",
    "        # Remove HTML tags and special characters\n",
    "        text = re.sub(r'</?.*?>', '', text)\n",
    "        # Remove non-alphanumeric characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "        # Remove digits\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def text_preprocessing(self, text, regex=False, remove_stop_word=False, lemmatisation=False, lower_case=False, return_tokens=False):\n",
    "        # Apply basic cleaning\n",
    "        if regex:\n",
    "            text = self.basic_cleaning(text)\n",
    "\n",
    "        if lower_case:\n",
    "            text = text.lower()\n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        if remove_stop_word:\n",
    "            tokens = [word for word in tokens if word not in self.stop_words]\n",
    "\n",
    "        if lemmatisation:\n",
    "            doc = self.nlp(' '.join(tokens))\n",
    "            tokens = [token.lemma_ for token in doc]\n",
    "\n",
    "        if return_tokens:\n",
    "            return tokens\n",
    "        else:\n",
    "            return \" \".join(tokens)\n",
    "    \n",
    "    def feature_extraction(self,tokens, ngram_range=(1, 1)):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f2529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7646, 13)\n",
      "(2434, 13)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "clean_operator = NLP_OPERATORS()\n",
    "\n",
    "# get the current path\n",
    "current_path = os.getcwd()\n",
    "\n",
    "\n",
    "# read the csv file\n",
    "df_mental = pd.read_csv(os.path.join(current_path, 'data', 'reddit_data', 'mental_reddit_posts.csv'))\n",
    "df_normal = pd.read_csv(os.path.join(current_path, 'data', 'reddit_data', 'normal_reddit_posts.csv'))\n",
    "\n",
    "\n",
    "print(df_mental.shape)\n",
    "print(df_normal.shape)                                                                                          \n",
    "df_mental['preprocessed_token_title'] = df_mental['title'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_mental['preprocessed_token_selftext'] =df_mental['selftext'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_mental['preprocessed_token_top_comments'] = df_mental['top_comments'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_mental.to_csv(os.path.join(current_path, 'data', 'reddit_data','clean', 'clean_mental_reddit_posts.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read all the csv files in beyondblue_data repository and concatenate them into a single dataframe\n",
    "df_beyondblue = pd.DataFrame()\n",
    "beyondblue_data_path = os.path.join(current_path, 'data', 'beyondblue_data')\n",
    "for file in os.listdir(beyondblue_data_path):\n",
    "    if file.endswith('.csv'):\n",
    "        temp_df = pd.read_csv(os.path.join(beyondblue_data_path, file))\n",
    "        df_beyondblue = pd.concat([df_beyondblue, temp_df], ignore_index=True)\n",
    "# remove duplicates by Post ID\n",
    "df_beyondblue = df_beyondblue.drop_duplicates(subset='Post ID').reset_index(drop=True)\n",
    "# Convert 'Post Date' to datetime format\n",
    "df_beyondblue['Post Date'] = pd.to_datetime(df_beyondblue['Post Date'], errors='coerce')\n",
    "# Sort by 'Post Date' in descending order\n",
    "df_beyondblue = df_beyondblue.sort_values(by='Post Date', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(df_beyondblue.shape)\n",
    "\n",
    "df_beyondblue['preprocessed_token_post_title'] = df_beyondblue['Post Title'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_beyondblue['preprocessed_token_post_content'] = df_beyondblue['Post Content'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_beyondblue['preprocessed_token_comments'] = df_beyondblue['Comments'].apply(lambda x: clean_operator.text_preprocessing(x, regex=True, remove_stop_word=True, lemmatisation=True, lower_case=True, return_tokens=True))\n",
    "df_beyondblue.to_csv(os.path.join(current_path, 'data', 'beyondblue_data','clean', 'clean_beyondblue_posts.csv'), index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4351b6e",
   "metadata": {},
   "source": [
    "feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60cc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa5bb6b",
   "metadata": {},
   "source": [
    "# CATEGORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_symptom_categories = [\n",
    "    \"Depression\",\n",
    "    \"Anxiety\",\n",
    "    \"Stress/Burnout\",\n",
    "    \"Loneliness\",\n",
    "    \"Low Self-Esteem\",\n",
    "    \"Trauma/PTSD\",\n",
    "    \"Anger/Irritability\",\n",
    "    \"Obsessive Thoughts\",\n",
    "    \"Addiction\"\n",
    "]\n",
    "\n",
    "suicide_and_selfharm_labels = [\n",
    "    \"Suicidal Ideation\",\n",
    "    \"Suicide Attempt\",\n",
    "    \"Self-Harm\",\n",
    "    \"Despair\",\n",
    "    \"Urgent Help Request\",\n",
    "    \"Grief After Suicide\",\n",
    "    \"Coping with Suicidal Thoughts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b75e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e969747d",
   "metadata": {},
   "source": [
    "# NETWORK VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be470570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0416cd9",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c2973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
